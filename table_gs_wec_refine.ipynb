{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1d7a76",
   "metadata": {},
   "source": [
    "#### Filtering out the nan seed of Gaussian scoring on WEC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c589b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import seed_everything, DEVICE\n",
    "from data_utils import *  \n",
    "from methods import * \n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"threadpoolctl\")\n",
    "\n",
    "# Data split\n",
    "def rcp_protocol_split(X, Y, cal_size=0.2, seed=42):\n",
    "    \"\"\"Splits data into Training, Calibration, and Test sets.\"\"\"\n",
    "    # Convert cal_size fraction to int if needed, here simplified\n",
    "    n_cal = int(len(X) * cal_size)    \n",
    "    X_rem, X_cal, Y_rem, Y_cal = train_test_split(X, Y, test_size=n_cal, random_state=seed)\n",
    "    X_tr, X_te, Y_tr, Y_te = train_test_split(X_rem, Y_rem, test_size=0.25, random_state=seed)\n",
    "    return X_tr, Y_tr, X_cal, Y_cal, X_te, Y_te\n",
    "\n",
    "\n",
    "# Main function\n",
    "def run_benchmark_suite():\n",
    "    seed_everything(42)\n",
    "    print(f\"Using Device: {DEVICE}\")\n",
    "\n",
    "    # Dataset registry\n",
    "    dataset_loaders = {    \n",
    "        \"WEC\": load_wec,                 \n",
    "    }\n",
    "    \n",
    "    alpha = 0.1\n",
    "    n_seeds = 20\n",
    "    \n",
    "    # Method registry \n",
    "    methods = [\n",
    "        # ('Split', run_split),\n",
    "        # ('PLCP-Pin-G20', lambda *a: run_plcp(*a, n_groups=20, score_type='pinball')),\n",
    "        # ('PLCP-Pin-G50', lambda *a: run_plcp(*a, n_groups=50, score_type='pinball')),\n",
    "        ('Gaussian-Scoring', run_gaussian_scoring),\n",
    "        # ('CQR-Pinball', lambda *a: run_cqr(*a, 'pinball')),\n",
    "        # ('CQR-ALD', lambda *a: run_cqr(*a, 'ald')),        \n",
    "        # ('RCP-Pinball', run_rcp),        \n",
    "        # ('RCP-ALD', lambda *a: run_rcp(*a, 'ald')),\n",
    "        # ('RCP-MultiHead', run_rcp_multi_head),                \n",
    "        \n",
    "        # # Colorful Pinball Variants (CPCP)\n",
    "        # ('CPCP-Split-0.02', lambda *a, **k: run_rcp_density_improved(*a, epsilon=0.02, mode='vanilla', **k)),                \n",
    "        # ('CPCP-Clip-0.02', lambda *a, **k: run_rcp_density_improved(*a, epsilon=0.02, mode='clip', clip_max=5.0, **k)),            \n",
    "        # ('CPCP-Mix-0.02', lambda *a, **k: run_rcp_density_improved(*a, epsilon=0.02, mode='mix', mix_ratio=0.5, **k)),\n",
    "        # ('CPCP-Clip+Mix-0.02', lambda *a, **k: run_rcp_density_improved(*a, epsilon=0.02, mode='clip', clip_max=5.0, mix_ratio=0.5, **k)),\n",
    "        # ('CPCP-Split-0.01', lambda *a, **k: run_rcp_density_improved(*a, epsilon=0.01, mode='vanilla', **k)),          \n",
    "        # ('CPCP-Clip+Mix-0.01', lambda *a, **k: run_rcp_density_improved(*a, epsilon=0.01, mode='clip', clip_max=5.0, mix_ratio=0.5, **k)),\n",
    "        # ('CPCP-Split-0.05', lambda *a, **k: run_rcp_density_improved(*a, epsilon=0.05, mode='vanilla', **k)),  \n",
    "        # ('CPCP-Clip+Mix-0.05', lambda *a, **k: run_rcp_density_improved(*a, epsilon=0.05, mode='clip', clip_max=5.0, mix_ratio=0.5, **k)),\n",
    "    ]\n",
    "    \n",
    "    for ds_name, loader in dataset_loaders.items():\n",
    "        print(f\"\\n>>>>>> Running {ds_name} <<<<<<\")\n",
    "        try: \n",
    "            X, Y = loader()\n",
    "            print(f\"Data Shape: {X.shape}, {Y.shape}\")\n",
    "        except Exception as e: \n",
    "            print(f\"Error loading {ds_name}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        results = {m[0]: [] for m in methods}\n",
    "        \n",
    "        total_start_time = time.time()\n",
    "\n",
    "        for seed in range(n_seeds):\n",
    "            seed_start_time = time.time()\n",
    "            print(f\"Seed {seed}...\", end=\"\", flush=True)\n",
    "            X_tr, Y_tr, X_cal, Y_cal, X_te, Y_te = rcp_protocol_split(X, Y, seed=42+seed)\n",
    "            \n",
    "            for name, func in methods:\n",
    "                try:\n",
    "                    # Pass extra args for CPCP methods\n",
    "                    if 'CPCP' in name or 'RCP-Density' in name:\n",
    "                        res = func(X_tr, Y_tr, X_cal, Y_cal, X_te, Y_te, alpha, dataset_name=ds_name, seed=seed)\n",
    "                    else:\n",
    "                        res = func(X_tr, Y_tr, X_cal, Y_cal, X_te, Y_te, alpha)\n",
    "                    results[name].append(res)\n",
    "                except Exception as e:\n",
    "                    print(f\" Err({name}:{e})\", end=\"\")\n",
    "\n",
    "            seed_duration = time.time() - seed_start_time\n",
    "            total_elapsed = time.time() - total_start_time\n",
    "            # print(\" Done\")\n",
    "            print(f\" Done (Seed Time: {seed_duration/60:.2f}m | Total Time: {total_elapsed/60:.2f}m)\")\n",
    "\n",
    "        # Summary & Save\n",
    "        torch.save(results, \"results_gs_wec_supp_norobust.pkl\")\n",
    "        summary_rows = []\n",
    "        for name, mets in results.items():\n",
    "            if not mets: continue\n",
    "            row = {'Method': name}\n",
    "            for k in ['Cov', 'Size', 'WSC', 'MSCE_10', 'MSCE_30', \"L1-ERT\", \"L2-ERT\"]:\n",
    "                vals = [m[k] for m in mets]\n",
    "                row[k] = f\"{np.mean(vals):.4f} ± {np.std(vals):.4f}\"\n",
    "\n",
    "            summary_rows.append(row)\n",
    "        \n",
    "        print(\"\\nSummary:\")\n",
    "        df_res = pd.DataFrame(summary_rows)\n",
    "        print(df_res)\n",
    "        \n",
    "        if not os.path.exists(\"./results\"): os.makedirs(\"./results\")\n",
    "        df_res.to_csv(f\"./results/{ds_name}_results_supp.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_benchmark_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d778454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Gaussian-Scoring | Total: 20 | Valid: 19 | Removed: 1\n",
      "\n",
      "Summary Table (Filtered):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Cov</th>\n",
       "      <th>Size</th>\n",
       "      <th>WSC</th>\n",
       "      <th>MSCE_10</th>\n",
       "      <th>MSCE_30</th>\n",
       "      <th>L1-ERT</th>\n",
       "      <th>L2-ERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian-Scoring</td>\n",
       "      <td>0.9006 ± 0.0032</td>\n",
       "      <td>1.6395 ± 0.2775</td>\n",
       "      <td>0.8259 ± 0.0347</td>\n",
       "      <td>0.0057 ± 0.0026</td>\n",
       "      <td>0.0082 ± 0.0033</td>\n",
       "      <td>0.0691 ± 0.0120</td>\n",
       "      <td>0.0079 ± 0.0035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Method              Cov             Size              WSC  \\\n",
       "0  Gaussian-Scoring  0.9006 ± 0.0032  1.6395 ± 0.2775  0.8259 ± 0.0347   \n",
       "\n",
       "           MSCE_10          MSCE_30           L1-ERT           L2-ERT  \n",
       "0  0.0057 ± 0.0026  0.0082 ± 0.0033  0.0691 ± 0.0120  0.0079 ± 0.0035  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs_results_dict = torch.load(\"results_gs_wec_supp_norobust.pkl\", weights_only=False)\n",
    "summary_rows = []\n",
    "\n",
    "# Iterate through each method in the dictionary\n",
    "for name, mets in gs_results_dict.items():\n",
    "    if not mets: \n",
    "        continue\n",
    "    \n",
    "    # Filter out seeds where 'Size' is NaN (treating them as anomalies)\n",
    "    # We check if 'Size' exists and is not a nan value\n",
    "    valid_seeds = [m for m in mets if 'Size' in m and not np.isnan(m['Size'])]\n",
    "    \n",
    "    # Optional: Print how many seeds were removed\n",
    "    print(f\"Method: {name} | Total: {len(mets)} | Valid: {len(valid_seeds)} | Removed: {len(mets) - len(valid_seeds)}\")\n",
    "    \n",
    "    if not valid_seeds:\n",
    "        print(f\"Warning: No valid seeds found for {name}\")\n",
    "        continue\n",
    "\n",
    "    # Prepare a row for the summary dataframe\n",
    "    row = {'Method': name}\n",
    "    \n",
    "    # List of metrics to process\n",
    "    metrics_list = ['Cov', 'Size', 'WSC', 'MSCE_10', 'MSCE_30', 'L1-ERT', 'L2-ERT']\n",
    "    \n",
    "    for k in metrics_list:\n",
    "        # Extract values for the current metric from valid seeds\n",
    "        vals = [m[k] for m in valid_seeds if k in m]\n",
    "        \n",
    "        if vals:\n",
    "            # Calculate mean and standard deviation\n",
    "            mean_val = np.mean(vals)\n",
    "            std_val = np.std(vals)\n",
    "            # Format as \"mean ± std\" (4 decimal places)\n",
    "            row[k] = f\"{mean_val:.4f} ± {std_val:.4f}\"\n",
    "        else:\n",
    "            row[k] = \"N/A\"\n",
    "            \n",
    "    summary_rows.append(row)\n",
    "\n",
    "print(\"\\nSummary Table (Filtered):\")\n",
    "df_res = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Reorder columns to ensure they match the desired output structure\n",
    "cols_order = ['Method', 'Cov', 'Size', 'WSC', 'MSCE_10', 'MSCE_30', 'L1-ERT', 'L2-ERT']\n",
    "df_res = df_res[cols_order]\n",
    "\n",
    "# Display the dataframe\n",
    "display(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfad608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv(\"results/WEC_gs_supp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d47c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
